\chapter{SPar: A session typed free monad EDSL for concurrency} \label{chap:spar}
In order to generate parallel code from ParAlg, we first introduce the syntax of our intermediate language, the session-typed free monad EDSL for concurrency hosted in Haskell (SPar). SPar is comprised of two components: Core and Proc. Core is the language expressing sequential computation while Proc is a monadic language with message-passing primitives, communicating Core expressions between different roles. We use a group of Proc interacting with each other to represent parallel computations. In addition, session typing a group of Procs ensures that the computation is deadlock-free \cite{langeVerifyingAsynchronousInteractions2019}.
\section{Computation: The Core EDSL}
Core is the elemental computation. The syntax of Core is mostly inspired by Alg \cite{AlgebraicMultipartyProtocol} and the work done by Svenningsson and Axelsson \cite{svenningssonCombiningDeepShallow2015}. For this project, we chose to implement Core syntax as small as possible without sacrificing expressibility.
\subsection{Syntax}
\begin{listing}[ht]
    \inputminted{Haskell}{spar/core.hs}
    \caption{The syntax of Core}
    \label{spar:code:core}
\end{listing}
The syntax of Core is shown in \coref{spar:code:core}. Inl and Inr are for the construction of sum types. Pair is responsible for constructing values of product types while Fst and Snd extract value from product type. Supporting sum, product and inductive types (see in the next section) is enough to express any data structure in any computation. In addition to these actions manipulating basic data structures, we have Lit which can be directly interpreted by the Haskell interpreter (see \secref{impl:sec:interp}) via unwrapping and Var, a constructor which is useful when what we do not actually evaluate the Core expression but inspect their static structure. It is used for code generation (see \secref{codegen:sec:core}) and session typing (see \secref{impl:sec:session}). Id is the identity function and Const is the constant function. Prim represents user defined functions takes, and two field: the name and the Haskell implementation. The first field will be useful in the code generation (see \secref{codegen:sec:core}) when applying user-defined function calls. The second field will be used by the Haskell interpreter directly when interpreting Prim expressions.    

\subsection{Representation of recursive data structures}
Core has primitives to operate on sum and product types. Representing recursive types like $\mu \text{list}. () + \text{Int} \times \text{list}$ will be covered in this section. The method is taken from the implementation of the Alg language in \cite{AlgebraicMultipartyProtocol}. First of all, we extend the core with the following two operations. \hask{In} represents the fold operation on iso-recursive types and \hask{Out} represents the unfold operation on iso-recursive types. \hask{:@:} is a type family which is a function acting on types instead of values. \hask{:@:} converts \hask{f} to sum and product type in Haskell which are \hask{(,)} and \hask{Either}. Consider a recursive type $\mu \alpha. \tau$, the type parameter \hask{t} is equivalent to $\alpha$, \hask{f :@: t} is equivalent to $\tau$ and the typeclass \hask{Data f t} is a recursive datatype equivalent to the fix-point of \hask{f}.
\begin{minted}{Haskell}
data Core a where
    In   :: Data f t => Core (f :@: t -> t)
    Out  :: Data f t => Core (t -> f :@: t)

type family (:@:) (a :: Poly Type) (b :: Type) :: Type where
    'PId :@: x = x
    'PK y :@: _ = y
    'PProd f g :@: x = (f :@: x, g :@: x)
    'PSum f g :@: x = Either (f :@: x) (g :@: x)

class Data (f :: Poly Type) t | t -> f where
    roll :: f :@: t -> t
    unroll :: t -> f :@: t
\end{minted}
A concrete example is shown below. We know a list has recursive type: $\mu \alpha. () + a \times \alpha$. So the \hask{f} is \hask{('PSum ('PK ())  ('PProd ('PK a) 'PId))} and we use Haskell list type \hask{[a]} to present $\alpha$ (equivalent to \hask{t} in  \hask{f :@: t}). \hask{f :@: t} is evaluated to the type \hask{Either () (a, [a])}.
\begin{minted}{Haskell}
instance Data ('PSum ('PK ())  ('PProd ('PK a) 'PId)) [a] where
    roll (Left _) = []
    roll (Right (a, b)) = a : b
  
    unroll [] = Left ()
    unroll (x:xs) = Right (x,xs)
\end{minted}

However, most of our examples use Prim for representing recursive data structure hiding the implementation details (see in \secref{codegen:sec:core}) In and Out are low-level operations and less used. % In conclusion, Core provides basic functionality, i.e Fst or Inl to process data and more importantly, Prim can hide the implementation details of the sequential computation. Prim turns out to be a useful in code generation. More details will be discussed in \secref{codegen:sec:core}.

\section{Communication: The Proc EDSL}
\begin{listing}[ht]
    \inputminted{Haskell}{spar/procf.hs}
    \caption{The algebra for message-passing}
    \label{spar:code:procf}
\end{listing}

Proc is a free monad EDSL for message passing. As introduced in the free monad section in the background, the first thing to do it to define the algebra of message-passing concurrency: \hask{ProcF} and \hask{Proc} is defined using free monad constructor and \hask{ProcF}. The definition is shown in the \coref{spar:code:procf}. Careful reader might notice that \hask{Proc} and \hask{ProcF} are defined mutually with each others in \hask{Branch}, \hask{Select} and \hask{Broadcast}.

The semantics will be defined in the next subsection in terms of a group of Proc programs because a single Proc program is either sequential or deadlock. The operational semantics is only worth discussing when given a group of Proc programs interacting with each others.

\section{Concurrent computation: A group of Proc}
We have introduced syntax for computation and communication. We also know that a single Proc expression is meaningless since there does not exist another party to interact with hence the computation has no progress. Naturally, we use a group of Proc to represent concurrent computations. To be more precise, a collection of Proc with their own role identifiers can be treated as a system of roles executing their own programs concurrently. In most of the cases, in order to make a group of Proc meaningful, we will allocate a start role in the system acting as the original data provider and a end role whose Proc program will receive data from others, process and output the final computation which is wrapped by the Pure constructor at the end of the Proc program. 

Readers might find it easy to visualize a group of Proc as a computation graph. The start role is the source node and the end role is the sink node. A pair of nodes are connected if they communicate data with each others.
\subsection{Operational semantics}
\begin{table}[ht]
\begin{align*}
    &(P_1, r_1) \Par (P_2, r_2) \Par \ldots \Par (P_n, r_n) \rightarrow \tag{Init}\\ 
    &\qquad \quad (P_1, r_1) \Par (P_2, r_2) \Par \ldots \Par (P_n, r_n) \Par \emptyset \notag\\ 
    &(\text{Free (Send $r_j$ $e$ next)}, r_i) \Par \ldots \Par h \rightarrow  \tag{Send}\\ 
    &\qquad \quad (\text{next} , r_i) \Par \ldots \Par h \cdot (r_i, r_j, v) \qquad (e \downarrow v) \notag\\ 
    &(\text{Free (Recv $r_i$ cont)}, r_j) \Par \ldots \Par (r_i, r_j, v) \cdot h \rightarrow  \tag{Recv}\\ 
    &\qquad \quad (p, r_j) \Par \ldots \Par h \qquad (\text{cont $v$} \downarrow p)\notag\\ 
    &(\text{Free (Select $r_j$ $e$ cont1 cont2 next)}, r_i) \Par \ldots \Par h \rightarrow  \tag{Sel-Left}\\ 
    &\qquad \quad (\text{cont1 $v$} \gg \text{next}, r_i) \Par \ldots \Par h \cdot (r_i, r_j, \text{L}) \qquad (e \downarrow v, \text{label}(v) \downarrow \text{L}) \notag\\ 
    &(\text{Free (Select $r_j$ $e$ cont1 cont2 next)}, r_i) \Par \ldots \Par h \rightarrow  \tag{Sel-Right}\\ 
    &\qquad \quad (\text{cont2 $v$} \gg \text{next}, r_i) \Par \ldots \Par h \cdot (r_i, r_j, \text{R}) \qquad (e \downarrow v, \text{label}(v) \downarrow \text{R}) \notag\\ 
    &(\text{Free (Branch $r_i$ next1 next2 cont)}, r_j) \Par \ldots \Par (r_i, r_j, \text{L}) \cdot h \rightarrow  \tag{Branch-Left}\\ 
    &\qquad \quad (\text{next1} >\!\!>\!\!= \text{cont}, r_j) \Par \ldots \Par h \notag\\ 
    &(\text{Free (Branch $r_i$ next1 next2 cont)}, r_j) \Par \ldots \Par (r_i, r_j, \text{R}) \cdot h \rightarrow  \tag{Branch-Right}\\ 
    &\qquad \quad (\text{next2} >\!\!>\!\!= \text{cont}, r_j) \Par \ldots \Par h \notag\\ 
    &(\text{Free (Broadcast [$r_{k_1}$, $\ldots$, $r_{k_n}$] $e$ cont1 cont2 next)}, r_i) \Par \ldots \Par h \rightarrow  \tag{Broadcast-1}\\ 
    &\qquad \quad (\text{Free (Select $r_{k_1}$ $v$ c c (Pure ()))}, r_i) \Par \ldots \Par h \notag\\ 
    & \qquad \text{where} \;(e \downarrow v, \text{c = Free (Broadcast [$r_{k_2}$, $\ldots$, $r_{k_n}$] cont1 cont2 next)}) \notag\\ 
    &(\text{Free (Broadcast [$r_{k_1}$] $e$ cont1 cont2 next)}, r_i) \Par \ldots \Par h \rightarrow  \tag{Broadcast-2}\\ 
    &\qquad \quad (\text{Free (Select $r_{k_1}$ $v$ cont1 cont2 next)}, r_i) \Par \ldots \Par h \qquad (e \downarrow v) \notag\\ 
    &(\text{Pure $v$}, r_i) \Par (P_i, r_i) \Par \ldots \Par (P_j, r_j) \Par h \rightarrow \tag{Pure}\\
    & \qquad \quad (P_i, r_i) \Par \ldots \Par (P_j, r_j) \Par h \notag\\ 
\end{align*}
\caption{Small step semantics for Proc}
\label{spar:sstep}
\end{table}
Due to the similarities between Proc and multiparty session calculus introduced in \cite{coppoGentleIntroductionMultiparty2015}, we borrow some syntax and operational semantics rules from their calculus to define the operational semantics of Proc. $P, Q$ denote Proc programs. A message queue is $h$ which contains messages $(q, p, v)$ meaning that the sender $q$ sends the receiver $p$ with value $v$. $h \cdot m$ is a message queue whose bottom element is message $m$. $h$ are runtime syntax to model the asynchronous message communication where the order of the messages are retained \cite{coppoGentleIntroductionMultiparty2015}. $e \downarrow v$ means the evaluation of the Core expression $e$ to the value $v$. \tabref{spar:sstep} shows the small step semantics for Proc. Rule (Init) describes the initialization of a group of Proc programs with an empty message queue at the beginning. Rule (Send) appends the value to the message queue. Its complementary rule: (Recv) will recv the value at the top of the message queue. Rule (Branch) is also the complementary rule of the rule (Sel). Broadcast is defined in terms of Select, and it broadcasts the label to a group of receivers. Even though its semantics can be expressed in terms of Select, the reason why we still treat broadcast as an independent operation in SPar is because 1) this operation is very common in communication, including Broadcast as a primitive operation is beneficial for user to write code 2) In the code generation stages, we can generate more efficient code for Broadcast operation instead of generating a series of Select operations. Broadcast operation can be treated as a syntax sugar in the Proc language. % Rule (Broadcast) multicasts the label to a group of receivers, adding a set of messages containing the label into the queue.

\subsection{Session types and duality checking} \label{spar:sec:session-typing}
Immediately, we notice that a Proc program can be typed by session types. \hask{Send} operation in ProcF corresponds to the type !$\langle$p, S$\rangle$.T, \hask{Select} corresponds to $\oplus \langle \text{p}, \{ l_i : T_i \}_{i \in I} \rangle$ and so on. One exception is the \hask{broadcast} operation which does not correspond to any type of the session types. We will discuss how to handle \hask{Broadcast} in \secref{impl:sec:session}. 

\begin{figure}[ht]
    \[
        \inference[Inst]{\Gamma \vdash e : \forall l. \text{Proc} \; L \; a}{\Gamma \vdash e : \text{Proc} \; ([\text{end}/l]L) \; a}
    \]
    \[
        \inference[Gen]{\Gamma \vdash e : \forall l. \text{Proc} \; L \; a, \quad \text{fresh} \; l}{\Gamma \vdash e : \text{Proc} \; ([l/\text{end}]L) \; a}
    \]
    \[
        \inference[Ret]{\Gamma |- v : a}{\Gamma |- \text{Pure $v$} : \forall l. \text{Proc} \; l \; a}
    \]
    \[
        \inference[Abs]{\Gamma, x : a |- e : \forall l. \text{Proc} \; L \; b}{\Gamma |- \lambda x. e : a \rightarrow \forall l. \text{Proc} \; L \; b}
    \]
    \[\inference[Bind]{\Gamma |- m : \forall l_1. \Mp{L_1}{a}, \quad \Gamma |- f : a \rightarrow \forall l_2. \Mp{L_2}{b}}{\Gamma |- m >\!\!>\!\!= f : \forall l_2. \Mp{[L_2/L_1]L_1}{b}}\]
    \[\inference[Send]{\Gamma |- v : a}{\Gamma |- \text{Free (Send $r$ $v$ (Pure $()$))} : \forall l. \Mp{(r!\langle a \rangle.l)}{()}}\]
    \[\inference[Recv]{}{\Gamma |- \text{Free (Recv $r$ $(\backslash v -> \text{Pure} \; v)$)} : \forall l. \Mp{(r?(a).l)}{a}}\]
    \[\inference[Select]{\Gamma |- v : a + b, \quad \Gamma |- f_1 : a \rightarrow \forall l_1 \Mp{L_1}{c}, \quad \Gamma |- f_2 : b \rightarrow \forall l_2. \Mp{L_2}{c}}{\Gamma |- \text{Free (Select $r$ $v$ $f_1$ $f_2$ (Pure $()$))} : \forall l. \Mp{r \oplus \{ L : [l/l_1]L_1, R: [l/l_2]L_2\}}{()}}\]
    % \[\inference[Broadcast]{\Gamma |- v : a + b, \quad \Gamma |- f_1 : a \rightarrow \forall l_1 \Mp{L_1}{c}, \quad \Gamma |- f_2 : b \rightarrow \forall l_2. \Mp{L_2}{c}}{\Gamma |- \text{Free (Broadcast $\{r_j\}_{\in J}$ $v$ $f_1$ $f_2$ (Pure $()$))} : \forall l. \Mp{\{r_j\}_{\in J} \oplus \{ L : [l/l_1]L_1, R: [l/l_2]L_2\}}{()}}\]
    \[\inference[Branch]{\Gamma |- \text{next1} : \forall l_1 \Mp{L_1}{c}, \quad \Gamma |- \text{next2} : \forall l_2. \Mp{L_2}{c}}
    {
        \begin{array}{@{}c@{}}
        \Gamma |- \text{Free (Branch $r$ next1 next2 ($\backslash x \rightarrow \text{Pure}\; x$))} : \\ \forall l. \Mp{r \; \& \{ L : [l/l_1]L_1, R: [l/l_2]L_2\}}{()}
        \end{array}
        % \Gamma |- \text{Free (Branch $r$ next1 next2 ($\backslash x \rightarrow \text{Pure}\; x$))} : \forall l. \Mp{r \; \& \{ L : [l/l_1]L_1, R: [l/l_2]L_2\}}{()}
    }\]
    \caption{Typing rules for Proc expressions}
    \label{spar:styperule}
\end{figure}

\figref{spar:styperule} shows the session typing rule for a Proc expression. We borrowed some notation from the work done \cite{AlgebraicMultipartyProtocol}. $\Gamma \vdash e : \text{Proc} \; L \; a$ is the type of a Proc expression that follows protocol $L$ and returns a value of type $a$. The types are parameterized by a variable $l$ representing the continuation of a local type $L$. The typing rules contain all the operations except \hask{Broadcast}. This is because \hask{Broadcast} can be expressed in terms of a series of \hask{Select} as explained in the previous subsection. So its session type $\oplus \{r_j\}_{j \in [1,n]} {L:L_1, R: L_2}$ can be expanded to $r_1 \oplus \{l: r_2 \oplus \{\ldots \oplus\{r_n \ldots\}\},\ldots\}_{l \in [L, R]}$. 

We have argued that a Proc program can be typed by multi-party session types. In order to utilize this property, we should check the duality of the each pair of Proc in the group. In short, duality check examines whether any pair of Proc in the system are complement with each other. If the duality properties is satisfied, the computation is guaranteed to be deadlock-free. This safety guarantee is useful and powerful in the application of parallel code generation. In this domain, SPar is considered to be the intermediate language. Passing duality check for the intermediate representation means that as long as we preserve types and communication pattern carefully in later stages of code generation pipeline, the generated code obtained will share the same non-trivial properties: communication safety, protocol fidelity and deadlock-freedom.

The work done by \cite{coppoGentleIntroductionMultiparty2015} constructed the theoretic foundation of algorithms for checking dualities and we will give an overview of the implementation in the \secref{impl:sec:session}.

\section{Conclusions}
In this section, we have introduced our intermediate language. It is human-friendly to use thanks to the monadic interface. In addition, communication and computation are independent in SPar. We can parameterize Proc with the type that represents sequential computation so that users can simply use their construction for sequential computation. More importantly, our strategy for parallelism is clear now. In a nutshell, we achieve parallelism by message-passing concurrency: spawning a group of threads on a multi-core CPU where each thread executes its corresponding Proc program.

Before jumping into the code generation, we will use next chapter to give an overview of some implementation challenges related to SPar first.