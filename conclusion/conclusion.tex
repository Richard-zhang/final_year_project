\chapter{Conclusions and future works}
\section{Conclusions}

Our goal was to implement a backend for code generation for Alg parallel language using a session-typed intermediate language. We not only achieved this but also developed a high-level framework for parallel computation. The most important result of the project is a framework that generates parallel C code along with local types describing the communication patterns by interpreting data-flow as communication, from Arrow based high-level expressions that can be easily formed, composed and manipulated by users with the help of the host language: Haskell.

In details, we developed SPar: a session-typed free monad EDSL for message-passing concurrency (see in \charef{chap:spar}) as our intermediate language. Also, we developed tools like local type inferrer to help us reason about the underlying communication structure with external tools by inferring session types from SPar expressions as well as a simulator to aid experimenting and act as a reference of semantics (see in \charef{chap:impl}). On top of this, we draw inspirations from the Arrow interface and developed SArrow: an interface for writing SPar expressions (see in \charef{chap:arrow}) to form complex computation patterns such as parallel divide-and-conquer and parallel map in a composite way. We designed a code generation backend from SPar to C. The core of the backend is Instr : a low-level EDSL for channel communication we created in \secref{codegen:sec:instr}. Code generation pipeline benefits from Instr's ease of transformation to a C AST. Finally, our benchmark (see in \charef{chap:eval}) shows that our framework can generate efficient parallel code and gain a notable performance boost compared to the sequential code. The best case gives us a speedup of nearly 12X when the input size is $2^{26}$ integers. In \secref{eval:sec:palgo}, we use a concrete example: expressing parallel merge sort in our framework to demonstrate that users can express computation in SArrow in a similar way as to how they would write for the sequential version and gain high-performance parallel code automatically.

In conclusion, with the recent release of AMD's latest generation of consumer CPUs featuring a processor with sixteen physical cores, Moore's law will be replaced by the addition of cores. No need to mention the area of high-performance computing where CPU with 64 cores are common. In contrast, most of the programmers have only written sequential code, and most of the algorithms about which students learn are not parallel. We hope this project can contribute its force on parallelism on CPUs, encouraging more and more programmers to take advantages of modern computing architectures.
\section{Future work}
There are many interesting future works that we would like to implement. We will select some of them to introduce:
\begin{itemize}
    \item \textbf{Optimization for benchmark.} Because of the time constraints, there are lots of space to optimize the generated code. We should do more fine-grained profiling on the generated code. It is interesting to use tools like EzTrace to trace and visualize the execution of all the threads. More importantly, reducing the size of the generated code by eliminating common sub-expressions will be useful. At the moment, there is much code duplication for communication among different roles. The only difference is that the role of participating in the communication. The size of generated code can be reduced a lot if we can extract the common part to a function parameterized by the roles participating. 
    \item \textbf{Integrated user experience.} As demonstrated in the evaluation chapter, users need to write the computation using the EDSL in Haskell and then generate C code. From then on, they need to finish the implementation of their atom functions in C. Finally, they can run the generated code with their data in C. The user experience is isolated when you have to write Haskell first and manually completed the generated code and run them in C. Instead, it will be great if we can provide an integrated user experience where the user does everything in Haskell from writing the high-level expression to collect computation results. This is possible thanks to packages like inline-C and foreign language interface in Haskell. User experience will be greatly improve if we can offer an interface in Haskell that looks like \hask{run :: SArrow a b -> (a -> b)}. This function will take a SArrow expression and produces a function that will convert a Haskell value into C data and execute the computation in C and copy back the C output by foreign language interface to Haskell. From the user pointer of way, it can be used the same as a normal Haskell function with type \hask{a -> b}. Forming a closed loop in Haskell would give us the best user interface and automate a large amount of boilerplate work.
    \item \textbf{Fine-grained control for strategies in role allocation.} We talked about how different role allocation strategies give us different parallel computation. It will be great if we parameterize the SArrow with role allocation strategies and adding ways to specify what strategy will be used at a different stage of the computation. This also opens the possibility for users to implement their strategies to customize their parallel computation tasks.
    \item \textbf{More customizations. } Similar to customized role allocation strategies, we can even have customized representation of sequential computation since the separation of the communication EDSL and the sequential computation EDSL. This can be done by parameterizing \hask{Core} in \hask{Proc}. This kind of work requires well-designed interfaces.
\end{itemize}