\chapter{SPar: A session typed free monad EDSL for concurrency}
In order to generate parallel code from ParAlg, we first introduce the syntax of our intermediate language, the session-typed free monad EDSL for concurrency hosted in Haskell (SPar). SPar are compromised of two components: Core and Proc. Core is the language expressing sequential computation while Proc is a monadic language with message-passing primitives, communicating Core expression between different roles. We use a group of Proc interacting with each other to represent parallel computations. In addition, session typing the group of Proc ensure the computation is deadlock-free. 
\section{Computation: The Core EDSL}
Core is the elemental computation. The syntax of Core is mostly inspired by Alg \cite{AlgebraicMultipartyProtocol} and FunC, a demo DSL defined in the work done by \cite{svenningssonCombiningDeepShallow2015}. For this project, we choose to implement Core syntax as small as possible without sacrificing expressibility.
\subsection{Syntax}
\begin{listing}[ht]
    \inputminted{Haskell}{spar/core.hs}
    \caption{The syntax of Core}
    \label{spar:code:core}
\end{listing}
The syntax of Core is shown in \coref{spar:code:core}. Inl and Inr are for the construction of sum type. Pair is responsible for constructing value of product type while Fst and Snd extract value from product type. Supporting sum type, product type and inductive type (see next section) is enough to express any data structure in any computation. In addition to these actions manipulating basic data structure, we have Lit which is used in the Haskell interpreter (see \secref{impl:sec:interp}) and benchmarking (see \secref{eval}) and Var, a constructor which is useful when what we do not actually evaluation the Core expression but inspect its static structure. It is used in the code generation (see \secref{codegen:sec:core}) and session typing (see \secref{impl:sec:session}). Id is similar to identity function and Const is similar to the const function in Haskell. Prim representing user defined functions takes two field name and the haskell implementation. The first field will be useful in the code generation (see \secref{codegen:sec:core}) when applying user-defined function calls. The second field will be used in the interpreter implementation.   

\subsection{Representation of recursive data structures}
Core has primitives to operate on sum and product types. Representing recursive type like $\mu \text{list}. () + \text{Int} \times \text{list}$ will be covered in this section. The method are taken from the implementation of Alg language in \cite{AlgebraicMultipartyProtocol}. First of all, we extend the core with the following two operation. \hask{In} represents the fold operation on iso-recursive types and \hask{Out} represents the unfold operation on iso-recursive types. Consider a recursive type $\mu \alpha. \tau$, the type parameter \hask{t} is equivalent to $\alpha$, \hask{f :@: t} is equivalent to $\tau$ and the typeclass \hask{Data f t} associate two types which is equivalent to $\mu \alpha. \tau$. \hask{:@:} is a type family which is a function acting on types instead of values. \hask{:@:} converts \hask{f} to sum and product type in Haskell which are \hask{(,)} and \hask{Either}.
\begin{minted}{Haskell}
data Core a where
    -- omit other constructors
    In   :: Data f t => Core (f :@: t -> t)
    Out  :: Data f t => Core (t -> f :@: t)

type family (:@:) (a :: Poly Type) (b :: Type) :: Type where
    'PId :@: x = x
    'PK y :@: _ = y
    'PProd f g :@: x = (f :@: x, g :@: x)
    'PSum f g :@: x = Either (f :@: x) (g :@: x)

class Data (f :: Poly Type) t | t -> f where
    roll :: f :@: t -> t
    unroll :: t -> f :@: t
\end{minted}
A concrete example is a list shown below. We know a list has recursive type: $\mu \alpha. () + a \times \alpha$. So the \hask{f} is \hask{('PSum ('PK ())  ('PProd ('PK a) 'PId))} and we use haskell list type \hask{[a]} to present $\alpha$ (equivalent to \hask{t} in  \hask{f :@: t}). \hask{f :@: t} is evaluated to the type \hask{Either () (a, [a])}.
\begin{minted}{Haskell}
instance Data ('PSum ('PK ())  ('PProd ('PK a) 'PId)) [a] where
    roll (Left _) = []
    roll (Right (a, b)) = a : b
  
    unroll [] = Left ()
    unroll (x:xs) = Right (x,xs)
\end{minted}

However, even though this way of representing recursive types is very smart but later we found out they are seldomly used in the code generation of parallel algorithms. Because functions processing complicated recursive data structure is usually represented by the Prim constructor hiding the implementation details so In and Out are too low-level operations and hence user are difficult to write complicated function by them. So in the conclusion, Core provides basic functionality, i.e Fst or Inl to process data and more importantly, Prim, a black box constructor hiding the implementation details of the sequential computation. Prim turn out to be a very useful abstraction in terms of code generation. More details will be discussed in the \secref{codegen:sec:core}.
\section{Communication: The Proc EDSL}
\subsection{Syntax and semantics}
\begin{listing}[ht]
    \inputminted{Haskell}{spar/procf.hs}
    \caption{The algebra for message-passing}
    \label{spar:code:procf}
\end{listing}
Proc will be a free monad EDSL for message passing. As introduced in the free monad section in the background, the first thing to do it to define the algebra of message-passing concurrency: \hask{ProcF} and \hask{Proc} is defined using free monad constructor and \hask{ProcF}. The definition is shown in the \coref{spar:code:procf}. Careful reader might notice that \hask{Proc} and \hask{ProcF} are defined mutually with each others in \hask{Branch}, \hask{Select} and \hask{Broadcast}. The reason will by covered in the explanation of semantics.

\hask{Send} takes

\subsection{Session typing}
\section{Concurrent computation: A group of Proc}
We have introduced syntax for computation and communication. We also know that a single Proc expression is meaningless since there does not exist another party to interact with this Proc hence the computation has no progress. Naturally, we use a group of Proc to represent concurrent computations. To be more precise, a collection of Proc with their own role identifiers can be treated as a system of roles executing their own programs concurrently. In most of the cases, in order to make the group of Proc meaningful, we will allocate a start role in the system acting as the original data provider and a end role whose Proc program will receive data from others, process and output the final computation which is wrapped by the Pure constructor at the end of the Proc program. 

Readers might find it easy to visualize the group of Proc as a computation graph. The start role is the source node and the end role is the sink node. A pair of nodes are connected if they communicate data with each others.

\subsection{Duality checks}
From the previous section, we reason that a Proc program can be typed  by multiparty session types. In order to utilize this property, we should check the duality of the each pair of Proc in the group. In short, duality check examine whether any pair of Proc in the system are complement with each other. If the duality properties is satisfied, the computation is guaranteed to be deadlock-free. The work done by \cite{coppoGentleIntroductionMultiparty2015} constructed the theoretic foundation of algorithms for checking dualities and we will give an overview of the implementation in the \secref{impl:sec:session}.
\section{Conclusions}
In this section, we have introduced our intermediate language. It is friendly to use thanks to the monadic interface. In addition, communication and computation are independent in SPar. We can make Proc to parameterized by the type represent sequential computation so users can simply use their construction for sequential computation if they found Core is limited. More importantly, our strategy for parallelism is clear now. In a nutshell, we achieve parallelism by message-passing concurrency: spawning a group of threads on a multi-core CPU where each thread executes its corresponding Proc program.

Before jumping into the code generation, we will use next chapter to give an overview of some implementation challenges related to SPar first.