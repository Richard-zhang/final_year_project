\chapter{Introduction}
\section{Motivation} \label{i:m}
Writing parallel programmes is not a trivial task. Parallel codes are hard to write because they usually written in low level languages with verbose and non-idiomatic decorations, hard to debug because machines, where codes are written, are usually different from machines where codes are intended to run and hard to maintain and reuse because even though the underlying algorithms are not changed, multiple version of parallel codes are needed to tackle various platform and evolution of architectures.

There're many on-going pieces of research in helping programmers write correct parallel programs smoothly. A common approach is to develop a higher level language and compiles programmes in this language to required parallel codes. There're many paradigms of the high-level languages to describe parallel programmes (TODO add some examples other than arrows). An example is to use arrow terms (Section \ref{b:arrows}) to describe data flow implicitly and hence generate parallel codes.

The workflow of writing parallel codes has evolved from writing parallel codes in the target platform directly to writing programmes in a high-level languages designed for parallel computation and then compiling to the target platform. In this project, we present a method to improve the "backend" of parallel code generation by introducing a monadic domain-specific language to be a bridge between high-level languages and target low-level parallel languages.

This specific language needs to be general enough so that different paradigms of a high-level language to describe parallel programs can be translated to these languages. It can be used to generate different parallel codes, e.g. MPI \footnote{Message Passing Interface (MPI) is a standardised and portable message-passing standard designed by a group of researchers from academia and industry to function on a wide variety of parallel computing architectures \cite{MessagePassingInterface2018}.}, Cuda. Moreover, it can be interpreted with a simulator to aid debugging parallel programs.

With the help of this intermediate languages, the implementation complexity is reduced from $O(M * N)$, where each of the M high-level languages needs to implement N compilers to generate parallel codes in N different platforms, to $O(M + N)$, where each high-level language implements a translation rule to the intermediate languages and intermediate languages implements N compilers to generate different target languages.

In addition, it couples with multiparty session type (MPST) \cite{coppoGentleIntroductionMultiparty2015}. It takes advantages of properties of MPST to enable aggressive optimisation but ensuring code correctness and allow more meaningful static analysis (TODO add more examples of possible kinds of static analysis).

\section{Objectives}
(TODO Need refinement and adding concrete details)
\begin{enumerate}
\item \textbf{Design}: Design the intermediate languages, argue its generanality and build its connection with MPST. 
\item \textbf{Tranlsation}: Give an example of how to translate high level languages to our languages. 
\item \textbf{Simulator}: Build a simulator to prove the correctness of code generation and act as a playground for experiments.
\item \textbf{Code generation}: Generate parallel codes in C.
\item \textbf{Static Analysis}: Give an example of how MPST can be used in improving the generated codes.
\end{enumerate}
\section{Challenges}
TODO
% \section{Contributions}